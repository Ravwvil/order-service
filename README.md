# Демонстрационный сервис с Kafka, PostgreSQL, кешем

Сервис для обработки и просмотра информации о заказах.

## Архитектура

Проект представляет собой систему для обработки заказов, использующую событийно-ориентированный подход и микросервисную архитектуру. Взаимодействие между компонентами построено на брокере сообщений **Kafka**, что обеспечивает слабую связанность и высокую отказоустойчивость.

**Поток данных:** `Publisher` ➝ `Kafka` ➝ `App (Consumer)` ➝ `PostgreSQL` & `Redis`

**Запрос данных:** `Frontend` ➝ `App (HTTP API)` ➝ `Redis (cache)` / `PostgreSQL (db)`

- **Publisher**: Генерирует и отправляет тестовые данные о заказах в Kafka. Это утилита для имитации внешнего источника данных.
- **App**: Основное приложение, которое:
    - Подписывается на топик в Kafka и получает данные о новых заказах.
    - Валидирует входящие данные.
    - Сохраняет их в основную базу данных **PostgreSQL**.
    - Кэширует данные в **Redis** для обеспечения быстрого доступа.
    - Предоставляет HTTP API с помощью chi роутера для получения информации о заказах по их UID. При запросе сначала проверяет наличие данных в Redis, и только в случае промаха кеша обращается к PostgreSQL.
- **Frontend**: Простой одностраничный веб-интерфейс для просмотра заказов по их уникальному идентификатору (UID). Отправляет запросы к HTTP API основного приложения.
- **Migrator**: Вспомогательный сервис для применения миграций к базе данных PostgreSQL с помощью golang-migrate. Запускается перед стартом основного приложения, чтобы подготовить схему БД.

## Тестирование

Проект покрыт как unit, так и интеграционными тестами для проверки корректности работы ключевых компонентов и их взаимодействия.

Для запуска всех тестов можно использовать команду:
```bash
make test
```
Или запустить тесты в специальном Docker-окружении, которое включает интеграционные тесты:
```bash
docker-compose --profile tests up --build
```

## Необходимые утилиты

Для запуска и работы с проектом вам понадобятся:

-   Docker
-   Docker Compose
-   Make (опционально, для удобства)

## Порядок запуска проекта

1.  **Клонируйте репозиторий:**
    ```bash
    git clone https://github.com/Ravwvil/order-service.git
    cd order-service
    ```

2.  **Настройте переменные окружения:**
    Переименуйте файл `.env.example` в `.env`. При необходимости вы можете изменить значения в этом файле.

3.  **Запустите сервисы:**
    Выполните следующую команду для сборки образов и запуска всех сервисов в фоновом режиме:
    ```bash
    make up
    ```
    Если у вас не установлен `make`, вы можете использовать команду `docker-compose`:
    ```bash
    docker-compose up -d --build
    ```
    В случае ошибок при сборке надо повторно запустить программу.
## Использование

1.  **Получите UID заказа:**
    После запуска всех сервисов, `publisher` автоматически сгенерирует и отправит 50 тестовых заказов в Kafka. Вы можете посмотреть логи `publisher`, чтобы получить `Order UID` заказов.
    ```bash
    docker-compose logs publisher
    ```
    В логах вы увидите секцию, похожую на эту:
    ```
    --- Published Order UIDs ---
    b563feb7b2b84b6test
    ...
    --------------------------
    ```
    Скопируйте любой UID из списка.

2.  **Откройте веб-интерфейс:**
    Перейдите в браузере по адресу [http://localhost:8080](http://localhost:8080).

3.  **Просмотрите заказ:**
    Вставьте скопированный `Order UID` в поле ввода на странице и нажмите "Get Order". Информация о заказе будет загружена и отображена в формате JSON.

## Доступные команды

Ниже приведены основные команды для управления сервисами. Вы можете использовать `make` для удобства или выполнять соответствующие команды `docker-compose` напрямую.

| Действие | Команда `make` | Команда `docker-compose`(на случай если нет Make) |
| --- | --- | --- |
| **Сборка и запуск** | `make up` | `docker-compose up -d --build` |
| **Остановка** | `make down` | `docker-compose down` |
| **Запуск тестов** | `make run-tests`| `docker-compose build tests && docker-compose run --rm tests`|
